{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayank-garg12/NLP-assignment-/blob/main/NLP_assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Assignment 1 — NLP PIPELINE`\n",
        "Submitted by: *Mayank Garg*\n",
        "\n",
        "Roll No.: *2301730272*"
      ],
      "metadata": {
        "id": "InjtMCoNPe45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install & Import Libraries"
      ],
      "metadata": {
        "id": "xpxcfJmCOOMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmMUI8fn-PgU",
        "outputId": "cb350af8-e6e8-4dde-ca75-1f958b873eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Paragraph"
      ],
      "metadata": {
        "id": "j79ew0q4OeUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"\n",
        "Modern Natural Language Processing systems rely heavily on large-scale text data\n",
        "to understand linguistic patterns and semantic relationships. In many applications,\n",
        "raw text is first converted into structured formats through preprocessing steps\n",
        "such as tokenization, normalization, and context-aware filtering. With advancements\n",
        "in deep learning, models are capable of capturing subtle variations in meaning,\n",
        "enabling tasks like text classification, sentiment interpretation, and automated\n",
        "summarization. The growing integration of NLP in software systems demonstrates\n",
        "how essential language understanding has become in contemporary computational workflows.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10HWgtl3-VnD",
        "outputId": "70b23e37-41f4-44e5-8402-f7caa6ad63e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            "\n",
            "Modern Natural Language Processing systems rely heavily on large-scale text data\n",
            "to understand linguistic patterns and semantic relationships. In many applications,\n",
            "raw text is first converted into structured formats through preprocessing steps\n",
            "such as tokenization, normalization, and context-aware filtering. With advancements\n",
            "in deep learning, models are capable of capturing subtle variations in meaning,\n",
            "enabling tasks like text classification, sentiment interpretation, and automated\n",
            "summarization. The growing integration of NLP in software systems demonstrates\n",
            "how essential language understanding has become in contemporary computational workflows.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "*Tokenization breaks text into smaller units like words.\n",
        "This helps in analyzing individual terms and preparing them for further tasks such as filtering, tagging, or modeling.*"
      ],
      "metadata": {
        "id": "ylM5aa63OndO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(paragraph)\n",
        "print(\"After Tokenization:\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At56B9xf-swq",
        "outputId": "dafd12d5-106a-4c7a-f751-93b987298a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Tokenization:\n",
            "['Modern', 'Natural', 'Language', 'Processing', 'systems', 'rely', 'heavily', 'on', 'large-scale', 'text', 'data', 'to', 'understand', 'linguistic', 'patterns', 'and', 'semantic', 'relationships', '.', 'In', 'many', 'applications', ',', 'raw', 'text', 'is', 'first', 'converted', 'into', 'structured', 'formats', 'through', 'preprocessing', 'steps', 'such', 'as', 'tokenization', ',', 'normalization', ',', 'and', 'context-aware', 'filtering', '.', 'With', 'advancements', 'in', 'deep', 'learning', ',', 'models', 'are', 'capable', 'of', 'capturing', 'subtle', 'variations', 'in', 'meaning', ',', 'enabling', 'tasks', 'like', 'text', 'classification', ',', 'sentiment', 'interpretation', ',', 'and', 'automated', 'summarization', '.', 'The', 'growing', 'integration', 'of', 'NLP', 'in', 'software', 'systems', 'demonstrates', 'how', 'essential', 'language', 'understanding', 'has', 'become', 'in', 'contemporary', 'computational', 'workflows', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopword Removal\n",
        "*Common words like “is,” “and,” “the,” etc., were removed because they do not add meaningful information.\n",
        "This step reduces noise and improves the quality of text analysis.*"
      ],
      "metadata": {
        "id": "ImaEy8ScO74D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "print(\"After Stopword Removal:\")\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbJhtMA2-whZ",
        "outputId": "540253ab-91ee-4321-b56e-e27b928bf4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Stopword Removal:\n",
            "['Modern', 'Natural', 'Language', 'Processing', 'systems', 'rely', 'heavily', 'large-scale', 'text', 'data', 'understand', 'linguistic', 'patterns', 'semantic', 'relationships', '.', 'many', 'applications', ',', 'raw', 'text', 'first', 'converted', 'structured', 'formats', 'preprocessing', 'steps', 'tokenization', ',', 'normalization', ',', 'context-aware', 'filtering', '.', 'advancements', 'deep', 'learning', ',', 'models', 'capable', 'capturing', 'subtle', 'variations', 'meaning', ',', 'enabling', 'tasks', 'like', 'text', 'classification', ',', 'sentiment', 'interpretation', ',', 'automated', 'summarization', '.', 'growing', 'integration', 'NLP', 'software', 'systems', 'demonstrates', 'essential', 'language', 'understanding', 'become', 'contemporary', 'computational', 'workflows', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming\n",
        "*Stemming reduces words to a basic form by cutting the ends. Example:\n",
        "“playing” → “play”\n",
        "“studies” → “studi”\n",
        "It is fast but not always perfect.*"
      ],
      "metadata": {
        "id": "-6ElHk8TPF6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "print(\"After Stemming:\")\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWRfjiJn_VLJ",
        "outputId": "3fdf30b8-87d0-4dc7-e343-6e992cf42a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Stemming:\n",
            "['modern', 'natur', 'languag', 'process', 'system', 'reli', 'heavili', 'large-scal', 'text', 'data', 'understand', 'linguist', 'pattern', 'semant', 'relationship', '.', 'mani', 'applic', ',', 'raw', 'text', 'first', 'convert', 'structur', 'format', 'preprocess', 'step', 'token', ',', 'normal', ',', 'context-awar', 'filter', '.', 'advanc', 'deep', 'learn', ',', 'model', 'capabl', 'captur', 'subtl', 'variat', 'mean', ',', 'enabl', 'task', 'like', 'text', 'classif', ',', 'sentiment', 'interpret', ',', 'autom', 'summar', '.', 'grow', 'integr', 'nlp', 'softwar', 'system', 'demonstr', 'essenti', 'languag', 'understand', 'becom', 'contemporari', 'comput', 'workflow', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization\n",
        "*Lemmatization was used to convert words to their base form.\n",
        "This helps group similar words together and reduces vocabulary size for better processing.*"
      ],
      "metadata": {
        "id": "0yi_q7C0PRTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "print(\"After Lemmatization:\")\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnXrWC43_YsB",
        "outputId": "a7b130ad-7856-409e-cd29-5c74a879c7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Lemmatization:\n",
            "['Modern', 'Natural', 'Language', 'Processing', 'system', 'rely', 'heavily', 'large-scale', 'text', 'data', 'understand', 'linguistic', 'pattern', 'semantic', 'relationship', '.', 'many', 'application', ',', 'raw', 'text', 'first', 'converted', 'structured', 'format', 'preprocessing', 'step', 'tokenization', ',', 'normalization', ',', 'context-aware', 'filtering', '.', 'advancement', 'deep', 'learning', ',', 'model', 'capable', 'capturing', 'subtle', 'variation', 'meaning', ',', 'enabling', 'task', 'like', 'text', 'classification', ',', 'sentiment', 'interpretation', ',', 'automated', 'summarization', '.', 'growing', 'integration', 'NLP', 'software', 'system', 'demonstrates', 'essential', 'language', 'understanding', 'become', 'contemporary', 'computational', 'workflow', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Conclusion*\n",
        "\n",
        "*The preprocessing steps used in this assignment helped convert raw text into a clean and structured format. By applying tokenization, stopword removal, stemming, and lemmatization, the paragraph became easier to analyze and ready for further NLP tasks. This workflow shows how basic text processing improves clarity and prepares data for more advanced techniques in natural language processing.*"
      ],
      "metadata": {
        "id": "2thaUQgmn69I"
      }
    }
  ]
}